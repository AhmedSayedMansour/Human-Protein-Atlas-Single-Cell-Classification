{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ahmed sayed mansour\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "  Downloading https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ahmed sayed mansour\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from hpacellseg==0.1.8) (1.5.4)\n",
      "Requirement already satisfied: pillow>=6.2.1 in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from hpacellseg==0.1.8) (8.2.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\ahmed sayed mansour\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from hpacellseg==0.1.8) (1.9.0+cu102)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in c:\\users\\ahmed sayed mansour\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from hpacellseg==0.1.8) (0.10.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\ahmed sayed mansour\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from hpacellseg==0.1.8) (7.1.2)\n",
      "Collecting pytorch_zoo@ https://github.com/haoxusci/pytorch_zoo/archive/master.zip\n",
      "  Downloading https://github.com/haoxusci/pytorch_zoo/archive/master.zip\n",
      "Collecting imageio>=2.6.1\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ahmed sayed mansour\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from imageio>=2.6.1->hpacellseg==0.1.8) (1.18.5)\n",
      "Collecting opencv-python>=4.2.0.32\n",
      "  Downloading opencv_python-4.5.3.56-cp38-cp38-win_amd64.whl (34.9 MB)\n",
      "Collecting scikit-image>=0.16.2\n",
      "  Downloading scikit_image-0.18.3-cp38-cp38-win_amd64.whl (12.2 MB)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (3.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (1.16.0)\n",
      "Collecting networkx>=2.0\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp38-cp38-win_amd64.whl (4.3 MB)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.8.30-py3-none-any.whl (171 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ahmed sayed mansour\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.4.0->hpacellseg==0.1.8) (3.7.4.3)\n",
      "Building wheels for collected packages: hpacellseg, pytorch-zoo\n",
      "  Building wheel for hpacellseg (setup.py): started\n",
      "  Building wheel for hpacellseg (setup.py): finished with status 'done'\n",
      "  Created wheel for hpacellseg: filename=hpacellseg-0.1.8-py3-none-any.whl size=14950 sha256=3019f92c6606d414e5de5ffe75e12e7503d49808a72dd5aba42055e1f679eeb8\n",
      "  Stored in directory: C:\\Users\\Ahmed Sayed Mansour\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-289ammyk\\wheels\\c0\\9f\\1a\\0d06f83f42c9aa212ea12a9008799a134ec3f1616c73cf8006\n",
      "  Building wheel for pytorch-zoo (setup.py): started\n",
      "  Building wheel for pytorch-zoo (setup.py): finished with status 'done'\n",
      "  Created wheel for pytorch-zoo: filename=pytorch_zoo-0.0.0-py3-none-any.whl size=30144 sha256=b6f7afb15002b0dc900cb9c9a531c2c6aae0b05ea5dd8300441525b6beec157e\n",
      "  Stored in directory: C:\\Users\\Ahmed Sayed Mansour\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-289ammyk\\wheels\\32\\9a\\77\\d91ff190ee49f0e3bf767d20c04b3d286015ae166070e270e3\n",
      "Successfully built hpacellseg pytorch-zoo\n",
      "Installing collected packages: tifffile, PyWavelets, networkx, imageio, scikit-image, pytorch-zoo, opencv-python, hpacellseg\n",
      "Successfully installed PyWavelets-1.1.1 hpacellseg-0.1.8 imageio-2.9.0 networkx-2.6.3 opencv-python-4.5.3.56 pytorch-zoo-0.0.0 scikit-image-0.18.3 tifffile-2021.8.30\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "import tensorflow as tf\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "import hpacellseg.cellsegmentator as cellsegmentator\r\n",
    "from hpacellseg.utils import label_cell, label_nuclei"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Input: list of image filters as png\r\n",
    "# Output: list of image filters as np.arrays\r\n",
    "def image_to_arrays(path):\r\n",
    "    \r\n",
    "    image_arrays = list()\r\n",
    "    for image in path:\r\n",
    "        array = np.asarray(Image.open(image))\r\n",
    "        image_arrays.append(array)\r\n",
    "        \r\n",
    "    return image_arrays"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Get single image that blends all RGBY into RGB\r\n",
    "# Introduce the images as arrays. Can use the function above.\r\n",
    "\r\n",
    "def get_blended_image(images): \r\n",
    "    # get rgby images for sample\r\n",
    "\r\n",
    "    # blend rgby images into single array\r\n",
    "    blended_array = np.stack(images[:-1], 2)\r\n",
    "\r\n",
    "    # Create PIL Image\r\n",
    "    blended_image = Image.fromarray( np.uint8(blended_array) )\r\n",
    "    return blended_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Introduce list of image filters\r\n",
    "# Returns a processed image ready for the CNN and an encoded label as tensor\r\n",
    "def image_prep(paths, label):\r\n",
    "\r\n",
    "    img = image_to_arrays(paths)\r\n",
    "    size = np.shape(img[0])[0]\r\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float32)\r\n",
    "    img = tf.reshape(img, (1, size, size, 3))\r\n",
    "    img = tf.image.resize(img, IMG_SIZE)\r\n",
    "\r\n",
    "    label = tf.strings.split(label, sep='|')\r\n",
    "    label = tf.strings.to_number(label, out_type=tf.int32)\r\n",
    "    label = tf.reduce_sum(tf.one_hot(indices=label, depth=19), axis=0)\r\n",
    "    label = tf.reshape(label, (1, 19))\r\n",
    "    \r\n",
    "    return img, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def apply_augmentation(image, label):\r\n",
    "    aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\r\n",
    "    aug_img.set_shape((IMG_SIZE[0], IMG_SIZE[0], 3))\r\n",
    "    \r\n",
    "    return aug_img, label"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def plot_hist(hist):\r\n",
    "    plt.plot(hist.history[\"accuracy\"])\r\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\r\n",
    "    plt.title(\"model accuracy\")\r\n",
    "    plt.ylabel(\"accuracy\")\r\n",
    "    plt.xlabel(\"epoch\")\r\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "DATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\r\n",
    "\r\n",
    "train = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "colours = ['_red.png', '_blue.png', '_yellow.png', '_green.png']\r\n",
    "#TRAIN = 'data/train'\r\n",
    "TRAIN = '../input/hpa-single-cell-image-classification/train'\r\n",
    "paths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's check out the label distribution frequency.\r\n",
    "label_counts = []\r\n",
    "for label in train['Label']:\r\n",
    "    sep = label.split('|')\r\n",
    "    for num in sep:\r\n",
    "        labels.append(int(num))\r\n",
    "counts = pd.value_counts(labels)\r\n",
    "\r\n",
    "# It's an ugly plot, but I'm trying to save some time here...\r\n",
    "plt.bar(x = counts.index,height=counts)\r\n",
    "plt.xticks(counts.index)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "titles = ['microtubules', 'nuclei', 'endoplasmic reticulum', 'protein of interest']\r\n",
    "fig, axs = plt.subplots(3, 4, figsize =(16,8))\r\n",
    "for entry in range(3):\r\n",
    "    for channel in range(4):\r\n",
    "        img = plt.imread(paths[entry][channel])\r\n",
    "        axs[entry, channel].imshow(img)        \r\n",
    "        if entry == 0:\r\n",
    "            axs[0, channel].set_title(titles[channel])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NUC_MODEL = \"./nuclei-model.pth\"\r\n",
    "CELL_MODEL = \"./cell-model.pth\"\r\n",
    "segmentator = cellsegmentator.CellSegmentator(\r\n",
    "    NUC_MODEL,\r\n",
    "    CELL_MODEL,\r\n",
    "    scale_factor=0.25,\r\n",
    "    device=\"cuda\",\r\n",
    "    padding=False,\r\n",
    "    multi_channel_model=True,\r\n",
    ")\r\n",
    "\r\n",
    "image = paths[4]\r\n",
    "arrays = image_to_arrays(image)\r\n",
    "nuclei = arrays[1]\r\n",
    "cell = arrays[:-1]\r\n",
    "\r\n",
    "# Nuclei segmentation\r\n",
    "nuc_segmentations = segmentator.pred_nuclei([nuclei])\r\n",
    "\r\n",
    "f, ax = plt.subplots(1, 2, figsize=(16,16))\r\n",
    "ax[0].imshow(arrays[1])\r\n",
    "ax[0].set_title('Original Nucleis', size=20)\r\n",
    "ax[1].imshow(nuc_segmentations[0])\r\n",
    "ax[1].set_title('Segmented Nucleis', size=20)\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Cell segmentation\r\n",
    "inter_step = [[i] for i in image[:-1]]\r\n",
    "cell_segmentations = segmentator.pred_cells(inter_step)\r\n",
    "\r\n",
    "f, ax = plt.subplots(1, 2, figsize=(16,16))\r\n",
    "ax[0].imshow(get_blended_image(arrays))\r\n",
    "ax[0].set_title('Original Cells', size=20)\r\n",
    "ax[1].imshow(cell_segmentations[0])\r\n",
    "ax[1].set_title('Segmented Cells', size=20)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Nuclei mask\r\n",
    "nuclei_mask = label_nuclei(nuc_segmentations[0])\r\n",
    "# Cell masks\r\n",
    "cell_nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\r\n",
    "# Plotting\r\n",
    "f, ax = plt.subplots(1, 3, figsize=(16,16))\r\n",
    "ax[0].imshow(nuclei_mask)\r\n",
    "ax[0].set_title('Nuclei Mask', size=20)\r\n",
    "ax[1].imshow(cell_nuclei_mask)\r\n",
    "ax[1].set_title('Cell Nuclei Mask', size=20)\r\n",
    "ax[2].imshow(cell_mask)\r\n",
    "ax[2].set_title('Cell Mask', size=20)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Let's stack the original image and the segmentation mask, to see how the segmentation worked out\r\n",
    "plt.figure(figsize=(20,20))\r\n",
    "plt.imshow(get_blended_image(arrays))\r\n",
    "plt.imshow(cell_mask, alpha=0.5)\r\n",
    "plt.title('Segmentation results', size=40)\r\n",
    "plt.axis('off')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Unique vector of cell_mask numbers\r\n",
    "numbers = set(np.ravel(cell_mask))\r\n",
    "numbers.remove(0)\r\n",
    "\r\n",
    "fig = plt.figure(figsize=(25,6*len(numbers)/4))\r\n",
    "index = 1\r\n",
    "\r\n",
    "ax = fig.add_subplot(len(numbers)//4+1, 4, index)\r\n",
    "ax.set_title(\"Complete Cell Mask\", size=20)\r\n",
    "plt.imshow(cell_mask)\r\n",
    "\r\n",
    "index += 1\r\n",
    "for number in numbers:\r\n",
    "    isolated_cell = np.where(cell_mask==number, cell_mask, 0)\r\n",
    "    ax = fig.add_subplot(len(numbers)//4+1, 4, index)\r\n",
    "    ax.set_title(\"Segment {number}\", size=20)\r\n",
    "    plt.imshow(isolated_cell)\r\n",
    "    index += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras import Model\r\n",
    "import wandb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "LABELS= {\r\n",
    "0: \"Nucleoplasm\",\r\n",
    "1: \"Nuclear membrane\",\r\n",
    "2: \"Nucleoli\",\r\n",
    "3: \"Nucleoli fibrillar center\",\r\n",
    "4: \"Nuclear speckles\",\r\n",
    "5: \"Nuclear bodies\",\r\n",
    "6: \"Endoplasmic reticulum\",\r\n",
    "7: \"Golgi apparatus\",\r\n",
    "8: \"Intermediate filaments\",\r\n",
    "9: \"Actin filaments\",\r\n",
    "10: \"Microtubules\",\r\n",
    "11: \"Mitotic spindle\",\r\n",
    "12: \"Centrosome\",\r\n",
    "13: \"Plasma membrane\",\r\n",
    "14: \"Mitochondria\",\r\n",
    "15: \"Aggresome\",\r\n",
    "16: \"Cytosol\",\r\n",
    "17: \"Vesicles and punctate cytosolic patterns\",\r\n",
    "18: \"Negative\"\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "IMG_SIZE = [224, 224]\r\n",
    "BATCH_SIZE = 64\r\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "\r\n",
    "colours = ['_red.png', '_blue.png', '_green.png']\r\n",
    "TRAIN = '../input/hpa-single-cell-image-classification/train'\r\n",
    "paths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "datasize = 1000\r\n",
    "trainsize = 700\r\n",
    "valsize = 150\r\n",
    "testsize = 150"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Processing the data for training:\r\n",
    "training_data = []\r\n",
    "for i,path in enumerate(paths[:trainsize]):\r\n",
    "    img, label = image_prep(path, train['Label'][i])\r\n",
    "    training_data.append([img,label])\r\n",
    "\r\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(([training_data[i][0] for i in range(len(training_data))], [training_data[i][1] for i in range(len(training_data))]))\r\n",
    "len(train_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#validation data\r\n",
    "val_data = []\r\n",
    "start_img = trainsize\r\n",
    "val_num = valsize\r\n",
    "for i,path in enumerate(paths[start_img:start_img+val_num]):\r\n",
    "    img, label = image_prep(path, train['Label'][i+start_img])\r\n",
    "    val_data.append([img,label])\r\n",
    "\r\n",
    "val_ds = tf.data.Dataset.from_tensor_slices(([val_data[i][0] for i in range(len(val_data))], [val_data[i][1] for i in range(len(val_data))]))\r\n",
    "len(val_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#test data\r\n",
    "test_data = []\r\n",
    "start_img_test = trainsize + valsize\r\n",
    "test_num = testsize\r\n",
    "for i,path in enumerate(paths[start_img_test:start_img_test+test_num]):\r\n",
    "    img, label = image_prep(path, train['Label'][i+start_img_test])\r\n",
    "    test_data.append([img,label])\r\n",
    "\r\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(([test_data[i][0] for i in range(len(test_data))], [test_data[i][1] for i in range(len(test_data))]))\r\n",
    "len(test_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_model = DenseNet121(include_top=False, weights='imagenet')\r\n",
    "base_model.trainable = True\r\n",
    "\r\n",
    "inputs = layers.Input((IMG_SIZE[0], IMG_SIZE[0], 3))\r\n",
    "\r\n",
    "x = base_model(inputs, training=True)\r\n",
    "x = layers.GlobalAveragePooling2D()(x)\r\n",
    "x = layers.Dropout(0.5)(x)\r\n",
    "outputs = layers.Dense(len(LABELS), activation='sigmoid')(x)\r\n",
    "\r\n",
    "tf.keras.backend.clear_session()\r\n",
    "\r\n",
    "model = Model(inputs, outputs)\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.keras.backend.clear_session()\r\n",
    "\r\n",
    "earlystopper = tf.keras.callbacks.EarlyStopping(\r\n",
    "    monitor='val_loss', patience=10, verbose=0, mode='min',\r\n",
    "    restore_best_weights=True\r\n",
    ")\r\n",
    "\r\n",
    "model.compile('adam', 'binary_crossentropy', metrics=[tf.keras.metrics.AUC(multi_label=True)])\r\n",
    "#model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\r\n",
    "#run = wandb.init(entity='ayush-thakur', project='hpa', job_type='train')\r\n",
    "\r\n",
    "hist = model.fit(train_ds, \r\n",
    "          epochs=10,\r\n",
    "          validation_data=val_ds,\r\n",
    "          verbose=1,\r\n",
    "          callbacks=[earlystopper]\r\n",
    "                )\r\n",
    "#plot_hist(hist)\r\n",
    "#run.finish()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "probs_densenet = model.predict(test_ds, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_labels = []\r\n",
    "test_labels_pre = []\r\n",
    "for i in range (testsize) :\r\n",
    "    test_labels.append(np.argmax(test_data[i][1]))\r\n",
    "    test_labels_pre.append(np.argmax(probs_densenet[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('train percentage :', (trainsize/datasize)*100)\r\n",
    "print('validation percentage :', (valsize/datasize)*100)\r\n",
    "print('test percentage :', (testsize/datasize)*100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report\r\n",
    "print(classification_report(test_labels, test_labels_pre))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "22e98dc126c11ed8b7da0abd0314319f11fb1123801a9053e96dbd9ca057f78a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}